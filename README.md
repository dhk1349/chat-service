# chat-service


Chatserver setup
- curl -fsSL https://ollama.com/install.sh | sh

On terminal1
- python main.py


On terminal2
- ollama serve 

On terminal3
- ollama run llama3:8b-instruct-q2_K
